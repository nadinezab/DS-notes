{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Bayes expands upon Bayes' theorem to multiple observations.\n",
    "\n",
    "Recall that Bayes' theorem is:  \n",
    "\n",
    "$$ \\Large P(A|B) = \\frac{P(B|A)\\bullet P(A)}{P(B)}$$\n",
    "\n",
    "Expanding to multiple features, the multinomial Bayes' formula is:  \n",
    "\n",
    "$$ \\Large P(y|x_1, x_2, ..., x_n) = \\frac{P(y)\\prod_{i}^{n}P(x_i|y)}{P(x_1, x_2, ..., x_n)}$$\n",
    "\n",
    "Here $y$ is an observation class while $x_1$ through $x_n$ are various features of the observation. Similar to linear regression, these features are assumed to be linearly independent.\n",
    "\n",
    "In the numerator, you multiply the product of the conditional probabilities $P(x_i|y)$ by the probability of the class y. The denominator is the overall probability (across all classes) for the observed values of the various features. In practice, this can be difficult or impossible to calculate. Fortunately, doing so is typically not required, as you will simply be comparing the relative probabilities of the various classes.\n",
    "\n",
    "To calculate each of the conditional probabilities in the numerator, $P(x_i|y)$, the Gaussian Naive Bayes algorithm traditionally uses the Gaussian probability density function to give a relative estimate of the probability of the feature observation, $x_i$, for the class $y$. Some statisticians don't agree with this as the probability of any point on a PDF curve is actually 0. \n",
    "\n",
    "With that, you have:  \n",
    "\n",
    "$$\\Large P(x_i|y) = \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}e^{\\frac{-(x-\\mu_i)^2}{2\\sigma_i^2}}$$\n",
    "\n",
    "Where $\\mu_i$ is the mean of feature $x_i$ for class $y$ and $\\sigma_i^2$ is the variance of feature $x_i$ for class $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   Target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris.data)\n",
    "X.columns = iris.feature_names\n",
    "\n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = ['Target']\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you calculate the mean and standard deviation within a class for each of the features. You'll then use these values to calculate the conditional probability of a particular feature observation for each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sepal length (cm)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sepal width (cm)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">petal length (cm)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">petal width (cm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.006</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>3.428</td>\n",
       "      <td>0.379064</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.173664</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.105386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.936</td>\n",
       "      <td>0.516171</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>4.260</td>\n",
       "      <td>0.469911</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.197753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.588</td>\n",
       "      <td>0.635880</td>\n",
       "      <td>2.974</td>\n",
       "      <td>0.322497</td>\n",
       "      <td>5.552</td>\n",
       "      <td>0.551895</td>\n",
       "      <td>2.026</td>\n",
       "      <td>0.274650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)           sepal width (cm)            \\\n",
       "                    mean       std             mean       std   \n",
       "Target                                                          \n",
       "0                  5.006  0.352490            3.428  0.379064   \n",
       "1                  5.936  0.516171            2.770  0.313798   \n",
       "2                  6.588  0.635880            2.974  0.322497   \n",
       "\n",
       "       petal length (cm)           petal width (cm)            \n",
       "                    mean       std             mean       std  \n",
       "Target                                                         \n",
       "0                  1.462  0.173664            0.246  0.105386  \n",
       "1                  4.260  0.469911            1.326  0.197753  \n",
       "2                  5.552  0.551895            2.026  0.274650  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = df.groupby('Target').agg(['mean', 'std'])\n",
    "aggs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities using the Gausian PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1553774365786804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_x_given_class(obs_row, feature, class_):\n",
    "    mu = aggs[feature]['mean'][class_]\n",
    "    std = aggs[feature]['std'][class_]\n",
    "    \n",
    "    # A single observation\n",
    "    obs = df.iloc[obs_row][feature] \n",
    "    \n",
    "    p_x_given_y = stats.norm.pdf(obs, loc=mu, scale=std)\n",
    "    return p_x_given_y\n",
    "\n",
    "# Notice how this is not a true probability; you can get values > 1\n",
    "p_x_given_class(0, 'petal length (cm)', 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(row):\n",
    "    c_probs = []\n",
    "    # range = number of classes\n",
    "    for c in range(3):\n",
    "        # Initialize probability to relative probability of class i.e. P(Y) in formula\n",
    "        p = len(df[df['Target'] == c])/len(df) \n",
    "        for feature in X.columns:\n",
    "            # Multiply by P(x | y)\n",
    "            p *= p_x_given_class(row, feature, c)\n",
    "        c_probs.append(p)\n",
    "        # Look for highest probability amongst the 3 values in c_probs\n",
    "        # np.argmax returns the indices of the maximum values along an axis.\n",
    "    return np.argmax(c_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.1\n",
       "sepal width (cm)     3.5\n",
       "petal length (cm)    1.4\n",
       "petal width (cm)     0.2\n",
       "Target               0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example using first observation\n",
    "row = 0\n",
    "df.iloc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predict_class(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly predicted 0.\n",
    "\n",
    "Let's evaluate our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.96\n",
       "False    0.04\n",
       "Name: Correct?, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column predictions by making predictions on each row\n",
    "df['Predictions'] =  [predict_class(row) for row in df.index]\n",
    "# Create a collumn correct set to True if Target matches Predictions\n",
    "df['Correct?'] = df['Target'] == df['Predictions']\n",
    "# Obtain normalized value counts of that column, ie % of correct predictions\n",
    "df['Correct?'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier was correct 96% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Bayes theorem:\n",
    "\n",
    " $$ \\large  P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$$\n",
    " \n",
    "Applied to a document, one common implementation of Bayes' theorem is to use a bag of words representation. A bag of words representation takes a text document and converts it into a word frequency representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 1,\n",
       " 'bag': 1,\n",
       " 'of': 1,\n",
       " 'words': 1,\n",
       " 'representation': 2,\n",
       " 'takes': 1,\n",
       " 'a': 2,\n",
       " 'text': 1,\n",
       " 'document': 1,\n",
       " 'and': 1,\n",
       " 'converts': 1,\n",
       " 'it': 1,\n",
       " 'into': 1,\n",
       " 'word': 1,\n",
       " 'frequency': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"A bag of words representation takes a text document and converts it into a word frequency representation\"\n",
    "bag = {}\n",
    "for word in doc.split():\n",
    "    # Get the previous entry, or 0 if not yet documented; add 1\n",
    "    bag[word] = bag.get(word, 0) + 1 \n",
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common example of using Bayes' theorem to classify documents is a spam filtering algorithm. To do this, you examine the question \"given this word (in the document) what is the probability that it is spam versus not spam?\" For example, perhaps you get a lot of \"special offer\" spam. In that case, the words \"special\" and \"offer\" may increase the probability that a given message is spam.\n",
    "\n",
    "You would have:\n",
    "\n",
    " $$ P(\\text{Spam | Word}) = \\dfrac{P(\\text{Word | Spam})P(\\text{Spam})}{P(\\text{Word})}$$  \n",
    "\n",
    "Using the bag of words representation, you can then define $P(\\text{Word | Spam})$ as\n",
    "\n",
    " $$P(\\text{Word | Spam}) = \\dfrac{\\text{Word Frequency in Document}}{\\text{Word Frequency Across All Spam Documents}}$$ \n",
    " \n",
    "However, this formulation has a problem: what if you encounter a word in the test set that was not present in the training set? This new word would have a frequency of **zero**! This would commit two grave sins. First, there would be a division by zero error. Secondly, the numerator would also be zero; if you were to simply modify the denominator, having a term with zero probability would cause the probability for the entire document to also be zero when you subsequently multiplied the conditional probabilities in Multinomial Bayes. To effectively counteract these issues, **Laplacian smoothing** is often used giving:   \n",
    "\n",
    " $$P(\\text{Word | Spam}) = \\dfrac{\\text{Word Frequency in Document} + 1}{\\text{Word Frequency Across All Spam Documents + Number of Words in Corpus Vocabulary}}$$  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
